from fastapi import HTTPException
from sqlalchemy.orm import Session
from utils.gpt_token_manager import get_openai_client
from utils.redis_client import redis_client
import json
from schemas.chatbot import ChatHistoryDto
from prompts.prompts import CHAT_PROMPT, EMOTION_ANALYSIS_PROMPT
from datetime import datetime
from core.emotion_config import EMOTION_NAME_MAP, STRENGTH_MAP
from crud import emo_calendar as emo_calendar_crud
from collections import Counter
import logging

REDIS_CHAT_HISTORY_KEY = "chat_history:{}"
HISTORY_LIMIT = 3 # ìµœê·¼ ëŒ€í™” ë‚´ì—­ ì €ì¥ ê°œìˆ˜

logger = logging. getLogger(__name__)
client = get_openai_client()

class ChatbotService:
    def __init__(self, db: Session):
        self.db = db
        self.client = get_openai_client()

    # 1. ì‚¬ìš©ì ëŒ€í™” ë¶„ì„ -> ê°ì • ë¶„ë¥˜
    # 2. ê°ì • ë¶„ë¥˜ì— ë”°ë¥¸ ëŒ€í™” ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
    # 3. DB ì €ì¥
    # 4. ì‚¬ìš©ì ì‘ë‹µ
    # TODO : ëŒ€í™” ë‚´ì—­ ê°€ì ¸ì˜¤ê¸°
    async def get_chat_history(self, member_seq: int, limit: int = None) -> list[ChatHistoryDto]:
        '''
            Redisì—ì„œ ëŒ€í™” ë‚´ì—­ ê°€ì ¸ì˜¤ê¸°
            - limitì´ Noneì´ë©´ ì „ì²´ ë‚´ì—­ ë°˜í™˜
            - limitì´ ì–‘ìˆ˜ë©´ ìµœê·¼ limitê°œ ë°˜í™˜
        '''

        key = REDIS_CHAT_HISTORY_KEY.format(member_seq)

        if limit is None:
            chat_history = await redis_client.lrange(key, 0, -1)
        else:
            chat_history = await redis_client.lrange(key, -limit, -1)

        chat_history_list = [ChatHistoryDto(**json.loads(history)) for history in chat_history]

        for item in chat_history_list:
            logger.info(f"{item}")
        return chat_history_list
        
    # TODO : ëŒ€í™” ë‚´ìš© ìš”ì•½ ì €ì¥ ìˆ˜ì •
    async def save_chat_summary(self, member_seq: int):
        '''ëŒ€í™” ì¢…ë£Œ í›„ ëŒ€í™” ë‚´ìš© ìš”ì•½ ì €ì¥
        '''
        key = REDIS_CHAT_HISTORY_KEY.format(member_seq)
        chat_history = self.get_chat_history(member_seq)

        if chat_history is None:
            return

        # ì‚¬ìš©ì ë©”ì‹œì§€, ê°ì •, ê°ì •ê°•ë„ ë§Œ ê°€ì ¸ì™€ì„œ Title, summary, ê°€ì¥ í¬ê²Œ ëŠë‚€ ê°ì • ì¶”ì¶œ
        user_messages = []
        emotion_list = []
        emotion_score_list = []
        for item in chat_history:
            user_message = item.get("user_message")
            emotion_seq = item.get("emotion_seq")
            emotion_score = item.get("strength")

            if user_message and emotion_seq and emotion_score:
                user_messages.append(f"{user_message} (ê°ì •: {emotion_seq}, ê°•ë„: {emotion_score})")
                emotion_list.append(emotion_seq)
                emotion_score_list.append(emotion_score)

        # ëŒ€í™” ë‚´ìš© ìš”ì•½, ê°ì •
        summary_prompt = self.build_summary_prompt(user_messages)
        summary = await self.call_openai(summary_prompt, "gpt-3.5-turbor") 
        title = summary.get("title")
        context = summary.get("context")

        # ê°€ì¥ ë§ì´ ë“±ì¥í•œ ê°ì •ì„ ê¸°ì¤€ìœ¼ë¡œ ëŒ€í‘œ ì •í•˜ê¸°
        most_common_emotion_seq = Counter(emotion_list).most_common(1)[0][0]
        avg_emotion_score = round(sum(emotion_score_list) / len(emotion_score_list), 1)

        await emo_calendar_crud.save_emotion_calender(
            self.db,
            member_seq,
            most_common_emotion_seq,
            avg_emotion_score,
            title,
            context,
            "ai"
        )

        await redis_client.delete(key)
        
    async def save_chat_history(self, member_seq: int, recode: ChatHistoryDto):
        '''ì‚¬ìš©ì ìƒíƒœ ì €ì¥ - í˜„ì¬ ëŒ€í™” ë‚´ì—­
        # Key : chat_history:{member_seq}
        # Value (JSON ë¬¸ìì—´)
        {
            "user_message": "ì˜¤ëŠ˜ ì§„ì§œ ë„ˆë¬´ í˜ë“¤ì—ˆì–´...",
            "bot_response": "ê´œì°®ì•„... ì •ë§ ë§ì´ í˜ë“¤ì—ˆê² êµ¬ë‚˜. ë‚´ê°€ ê³ì— ìˆì–´ì¤„ê²Œ... ğŸ˜¢ğŸŒ§ï¸",
            "emotion": "2",
            "strength": "3",
            "timestamp": 1717482053.1252
        }
        '''
        key = REDIS_CHAT_HISTORY_KEY.format(member_seq)
        
        # json í˜•ì‹ìœ¼ë¡œ value ì €ì¥
        recode_json = recode.model_dump_json()
        await redis_client.rpush(key, recode_json)
        # await redis_client.ltrim(key, -HISTORY_LIMIT, -1)

        logger.info(f"ğŸ’¬ ëŒ€í™” ë‚´ì—­ ì €ì¥ : {recode_json}")
        
    def build_emotion_prompt(self, user_message: str):
        '''ì‚¬ìš©ì ë©”ì‹œì§€ì— ë”°ë¥¸ ê°ì • ë¶„ë¥˜
        JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜
        {
            "emotion_seq": 1,
            "strength": 2
        }
        '''
        return [
            {"role": "system", "content": EMOTION_ANALYSIS_PROMPT},
            {"role": "user", "content": user_message}
        ]


    def build_chatbot_prompt(self,user_message: str, chat_history: list[ChatHistoryDto] | None = None):
        '''
        ì±—ë´‡ ì‘ë‹µ ìƒì„±
        '''
        prompt = [{"role": "system", "content": CHAT_PROMPT}]
    
        for record in chat_history:
            prompt.append({"role": "user", "content": f"{record.user_message} (ê°ì •: {EMOTION_NAME_MAP[record.chatbot_response.get('emotion_seq')]}, ê°•ë„: {STRENGTH_MAP[record.chatbot_response.get('emotion_score')]})"})
            prompt.append({"role": "assistant", "content": json.dumps(record.chatbot_response, ensure_ascii=False)})
            logger.info(f"{record}")
        
        prompt.append({"role": "user", "content": user_message})
        return prompt
        
    
    async def get_chatbot_response(self, member_seq: int, user_message: str):
        # 1. ìµœê·¼ ëŒ€í™” ë‚´ì—­ ê°€ì ¸ì˜¤ê¸°
        chat_history = await self.get_chat_history(member_seq, HISTORY_LIMIT)
        # 2. ê°ì • ë¶„ë¥˜ - í˜„ì¬ ëŒ€í™”
        # emotion_analysis_prompt = self.build_emotion_prompt(user_message)
        # emotion_response = await self.call_openai(model="gpt-3.5-turbo", prompt=emotion_analysis_prompt)
        
        # try :
        #     emotion_response = json.loads(emotion_response)
        # except json.JSONDecodeError as e:
        #     logger.error(f"ê°ì • ë¶„ì„ ì‹¤íŒ¨: {e}")
        #     raise HTTPException(status_code=500, detail="ê°ì • ë¶„ì„ ì‹¤íŒ¨")
        
        # logger.info(f"ğŸš¨ìµœê·¼ ëŒ€í™” ë‚´ì—­ ê²°ê³¼ : {chat_history}")
        # 3. ì±—ë´‡ ì‘ë‹µ ìƒì„± string
        chatbot_prompt = self.build_chatbot_prompt(user_message, chat_history)
        chatbot_response = await self.call_openai(prompt=chatbot_prompt, model="gpt-4o-mini")
        logger.info(chatbot_response)

        try: 
            chatbot_response_json = json.loads(chatbot_response)
            # ëŒ€í™” ë‚´ì—­ ì €ì¥ -redis
            await self.save_chat_history(
                    member_seq, 
                    ChatHistoryDto(
                        user_message=user_message,
                        chatbot_response=chatbot_response_json,
                        created_at=datetime.now(),
                    ),
                )
        except json.JSONDecodeError as e:
            # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ë¡œê·¸ ì¶œë ¥
            logger.error(f"ì±—ë´‡ ì‘ë‹µ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            raise HTTPException(status_code=500, detail="ì±—ë´‡ ì‘ë‹µ JSON íŒŒì‹± ì‹¤íŒ¨")

            

        return chatbot_response_json
    
    # GPT ëª¨ë¸ í˜¸ì¶œ
    async def call_openai(self, prompt: str, model: str = "gpt-3.5-turbor", temperature: float = 1.0):
        response = client.chat.completions.create(
            model=model,
            messages=prompt,
            temperature=temperature,
            stream=False,
        )
        return response.choices[0].message.content

    async def get_chatbot_response_no_user(self, user_message: str, model: str = "gpt-3.5-turbo"):
        '''ë¹„íšŒì›ìš© ëŒ€í™” ì‘ë‹µ (íˆìŠ¤í† ë¦¬ ì €ì¥ ì•ˆ í•¨)'''
        
        if not user_message.strip():
            raise ValueError("user_message cannot be empty")

        prompt = [
            {"role": "system", "content": CHAT_PROMPT},
            {"role": "user", "content": user_message}
        ]

        response =await self.call_openai(prompt, model)
        response_json = json.loads(response)

        
        return response_json.get("response")


    
